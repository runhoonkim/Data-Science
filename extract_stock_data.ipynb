{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f743759-690f-4b1e-ab7d-bf705e2ab532",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install yfinance\n",
    "!pip install matplotlib\n",
    "# !pip install pandas==1.3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cad211f-3b33-4d66-85ee-e02dc4ea04d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bea10-5e01-4151-b9ab-8cc85d60ef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple = yf.Ticker(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d661da98-58f9-42af-8652-f21dbc7c68ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/data/apple.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c6b427-122a-44fc-a654-0641aa234711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('apple.json') as json_file:\n",
    "    apple_info = json.load(json_file)\n",
    "    # Print the type of data variable    \n",
    "    #print(\"Type:\", type(apple_info))\n",
    "apple_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38abdc9e-6864-4300-91d3-b9b2ebcdd33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_info['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9a6d51-e682-46e9-8b0f-cc5e0a92fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_share_price_data = apple.history(period=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3523f105-5666-43bb-8dfa-9aa57eca417b",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_share_price_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc18abcd-294f-4a2d-9424-f0a70130ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_share_price_data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85876fbe-6918-48c9-a16a-b7cafab3b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple_share_price_data.plot(x=\"Date\", y=\"Open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7a6303-b4d3-4449-a39a-8db445bf2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple.dividends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96b7752-6e13-4e32-8d7c-c59d7cee6485",
   "metadata": {},
   "outputs": [],
   "source": [
    "apple.dividends.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545028a4-b829-45cd-90d4-c5673d3a5743",
   "metadata": {},
   "outputs": [],
   "source": [
    "amd = yf.Ticker(\"AMD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cdd4cf-e6ab-4e60-8452-5a87eb6ac35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/data/amd.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09fb7a2-6c82-40c6-b02f-fb81834ffed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('amd.json') as json_file:\n",
    "    amd_info = json.load(json_file)\n",
    "    # Print the type of data variable    \n",
    "    #print(\"Type:\", type(apple_info))\n",
    "amd_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e41ae5-d55e-42ea-9e20-aef002e751f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c38ac3-3eed-42f3-acb8-8e21279ffde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "\n",
    "msft = yf.Ticker(\"MSFT\")\n",
    "print(msft)\n",
    "\"\"\"\n",
    "returns\n",
    "<yfinance.Ticker object at 0x1a1715e898>\n",
    "\"\"\"\n",
    "\n",
    "# get stock info\n",
    "msft.info\n",
    "\n",
    "\"\"\"\n",
    "returns:\n",
    "{\n",
    " 'quoteType': 'EQUITY',\n",
    " 'quoteSourceName': 'Nasdaq Real Time Price',\n",
    " 'currency': 'USD',\n",
    " 'shortName': 'Microsoft Corporation',\n",
    " 'exchangeTimezoneName': 'America/New_York',\n",
    "  ...\n",
    " 'symbol': 'MSFT'\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# get historical market data\n",
    "msft.history(period=\"max\")\n",
    "\"\"\"\n",
    "returns:\n",
    "              Open    High    Low    Close      Volume  Dividends  Splits\n",
    "Date\n",
    "1986-03-13    0.06    0.07    0.06    0.07  1031788800        0.0     0.0\n",
    "1986-03-14    0.07    0.07    0.07    0.07   308160000        0.0     0.0\n",
    "...\n",
    "2019-04-15  120.94  121.58  120.57  121.05    15792600        0.0     0.0\n",
    "2019-04-16  121.64  121.65  120.10  120.77    14059700        0.0     0.0\n",
    "\"\"\"\n",
    "\n",
    "# show actions (dividends, splits)\n",
    "msft.actions\n",
    "\"\"\"\n",
    "returns:\n",
    "            Dividends  Splits\n",
    "Date\n",
    "1987-09-21       0.00     2.0\n",
    "1990-04-16       0.00     2.0\n",
    "...\n",
    "2018-11-14       0.46     0.0\n",
    "2019-02-20       0.46     0.0\n",
    "\"\"\"\n",
    "\n",
    "# show dividends\n",
    "msft.dividends\n",
    "\"\"\"\n",
    "returns:\n",
    "Date\n",
    "2003-02-19    0.08\n",
    "2003-10-15    0.16\n",
    "...\n",
    "2018-11-14    0.46\n",
    "2019-02-20    0.46\n",
    "\"\"\"\n",
    "\n",
    "# show splits\n",
    "msft.splits\n",
    "\"\"\"\n",
    "returns:\n",
    "Date\n",
    "1987-09-21    2.0\n",
    "1990-04-16    2.0\n",
    "...\n",
    "1999-03-29    2.0\n",
    "2003-02-18    2.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8f0329-4fdc-4d45-b633-27f7d95b7c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "data = yf.download(\"SPY AAPL\", start=\"2017-01-01\", end=\"2017-04-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3097a49f-d9c4-440b-abb2-eed6e5136ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "data = yf.download(\"SPY AAPL\", start=\"2017-01-01\", end=\"2017-04-30\",\n",
    "                   group_by=\"ticker\")\n",
    "\n",
    "# To access the closing price data for SPY, you should use: data['SPY']['Close'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8517db1d-d330-4128-ab6c-adfb9a57758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_datareader import data as pdr\n",
    "\n",
    "import yfinance as yf\n",
    "yf.pdr_override() # <== that's all it takes :-)\n",
    "\n",
    "# download dataframe using pandas_datareader\n",
    "data = pdr.get_data_yahoo(\"SPY\", start=\"2017-01-01\", end=\"2017-04-30\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06324bd9-ff51-4473-a260-507deb074637",
   "metadata": {},
   "outputs": [],
   "source": [
    "$ pip install yfinance --upgrade --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe652f57-d4aa-4cb8-9484-48a8ecac2934",
   "metadata": {},
   "source": [
    "# Extract Stock Data Using Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f1ed9-c450-4020-9fda-b41c3a63f8b2",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    \n",
    "1. Extracting data using BeautifulSoup\n",
    "   \n",
    "    <ul> \n",
    "    <li> Download the web page Using Requests Library </li>\n",
    "    <li> Parse HTML on a web page using BeautifulSoup </li>\n",
    "    <li> Extract data and duild a data frame </li>\n",
    "\n",
    "    </ul>\n",
    "\n",
    "2. Extracting data using pandas\n",
    "3. Exercise\n",
    "<p>\n",
    "    Estimated Time Needed: <strong>30 min</strong></p>\n",
    "</div>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c1690-7142-4593-86a7-62789d34da51",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install requests\n",
    "!pip install bs4\n",
    "!pip install html5lib \n",
    "!pip install lxml\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fad3ff-4949-4f6a-bf52-1547821af808",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5366cd7d-83ac-4064-a14d-639602966528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f00640-0ba9-4af4-887e-6e123ee658d7",
   "metadata": {},
   "source": [
    "# Steps for extracting the data\n",
    "1. Send an HTTP request to the web page using the requests library.\n",
    "2. Parse the HTML content of the web page using BeautifulSoup.\n",
    "3. Identify the HTML tags that contain the data you want to extract.\n",
    "4. Use BeautifulSoup methods to extract the data from the HTML tags.\n",
    "5. Print the extracted data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34285866-c73f-452c-922a-ec83daa74b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef31b281-a3c7-447f-ae8f-4d4209eabe85",
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = requests.get(url).text\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59d50b4-28a2-4b12-a940-b82739aca5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0057e57a-5569-4a09-a379-15f2041d6368",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_data = pd.DataFrame(columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a5ad66-8644-44b9-8342-42e302fd2599",
   "metadata": {},
   "source": [
    "<hr>\n",
    "<hr>\n",
    "<center>\n",
    "\n",
    "### Working on HTML table  </center>\n",
    "<br>\n",
    "\n",
    "These are the following tags which are used while creating HTML tables.\n",
    "\n",
    "* &lt;table&gt;: This tag is a root tag used to define the start and end of the table. All the content of the table is enclosed within these tags. \n",
    "\n",
    "\n",
    "* &lt;tr&gt;: This tag is used to define a table row. Each row of the table is defined within this tag.\n",
    "\n",
    "* &lt;td&gt;: This tag is used to define a table cell. Each cell of the table is defined within this tag. You can specify the content of the cell between the opening and closing <td> tags.\n",
    "\n",
    "* &lt;th&gt;: This tag is used to define a header cell in the table. The header cell is used to describe the contents of a column or row. By default, the text inside a <th> tag is bold and centered.\n",
    "\n",
    "* &lt;tbody&gt;: This is the main content of the table, which is defined using the <tbody> tag. It contains one or more rows of <tr> elements.\n",
    "\n",
    "<hr>\n",
    "<hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21a7503-0d0d-46a8-8418-519087d79a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we isolate the body of the table which contains all the information\n",
    "# Then we loop through each row and find all the column values for each row\n",
    "for row in soup.find(\"tbody\").find_all('tr'):\n",
    "    col = row.find_all(\"td\")\n",
    "    date = col[0].text\n",
    "    Open = col[1].text\n",
    "    high = col[2].text\n",
    "    low = col[3].text\n",
    "    close = col[4].text\n",
    "    adj_close = col[5].text\n",
    "    volume = col[6].text\n",
    "    \n",
    "    # Finally we append the data of each row to the table\n",
    "    netflix_data = pd.concat([netflix_data,pd.DataFrame({\"Date\":[date], \"Open\":[Open], \"High\":[high], \"Low\":[low], \"Close\":[close], \"Adj Close\":[adj_close], \"Volume\":[volume]})], ignore_index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c45a3-0a2c-4ba7-97dd-804fa57a5824",
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb49915-1702-44f0-9093-00c4e9367c8d",
   "metadata": {},
   "source": [
    "# Extracting data using `pandas` library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e4657a-1c9c-42ae-b8bf-43ef7b81b247",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_html_pandas_data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43e9384-2606-4835-a231-89db1cb47387",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_html_pandas_data = pd.read_html(str(soup))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f24aae9-9e16-4a73-9be2-033a091e6218",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_html_pandas_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m netflix_dataframe \u001b[38;5;241m=\u001b[39m read_html_pandas_data[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m netflix_dataframe\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'read_html_pandas_data' is not defined"
     ]
    }
   ],
   "source": [
    "netflix_dataframe = read_html_pandas_data[0]\n",
    "\n",
    "netflix_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66182817-8e31-4f33-aa70-62664de44c53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0908dfa6-0beb-4680-bf87-c79782915edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6c05cf-507d-44bb-8148-f0ab928538b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eec0fe-37b8-40f0-8dde-de5de949afb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c33369-670d-41c3-b23e-c60eb27ec164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
